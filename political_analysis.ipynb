{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TikTok Political Analysis\n",
    "## ~Objectives\n",
    "### Problems & Questions\n",
    "__How can we better develop educational materials to meet kids where they are?__\n",
    "- is it worth it to spend money to advertise to youth for political campaigns - are they engaging with current events?\n",
    "- what are kids talking about & why? What does our education system tell them and not tell them\n",
    "\n",
    "### Goals\n",
    "- understanding how age/youth impacts political indoctrination\n",
    "- understanding social impacts of political events\n",
    "- to understand colloquial knowledge of political concepts\n",
    "\n",
    "## ~Scope\n",
    "- daily batch updates\n",
    "- parsed news events triggers TikTok & twitter queries \n",
    "- topic counts 3 days before event cumulatively added to event day & 3 days following event\n",
    "- see trend lines of engagement on Twitter & TikTok\n",
    "\n",
    "### Overview:\n",
    "- Use NewsAPI to find top news by day\n",
    "- Parse news story title & article into individual words/phrases\n",
    "- Count most important individual words & phrases\n",
    "- Use top 3 most important words & phrases to create rules for searching the Twitter API\n",
    "- Count number of tweets mentioning words & phrases filtered by rules\n",
    "- Use top 3 words & phrases to find similar tags on TikTok API\n",
    "- Count number of TikTok challenges/tags/captions with top words & phrases\n",
    "\n",
    "## ~Extras\n",
    "- age inference of users\n",
    "- sentiment analysis (TextBlob)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Install Dependencies & Import Modules\n",
    "- Newsapi-python: pip install newsapi-python\n",
    "- Tweepy (install without virtual environment): pip install tweepy\n",
    "- playwright: pip install playwright\n",
    "                playwright install\n",
    "- TikTokApi (install without virtual environment): pip install TikTokApi --upgrade\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from datetime import date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import logging\n",
    "import configparser\n",
    "from timer import Timer\n",
    "from numpy import datetime64\n",
    "from datetime import date, datetime, timedelta\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter\n",
    "import math\n",
    "import tweepy  # python package for accessing Tweet streaming API\n",
    "from tweepy import API\n",
    "from tweepy import Stream\n",
    "import urllib.parse\n",
    "from TikTokApi import TikTokApi\n",
    "from selenium import webdriver\n",
    "import psycopg2 # alts: SQLalchemy - warning: not as simple\n",
    "from psycopg2 import Error\n",
    "import re\n",
    "import sys\n",
    "import geocoder\n",
    "from helper_functions import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configure using config.ini file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = configparser.ConfigParser()\n",
    "c.read('config.ini')\n",
    "\n",
    "# config credentials\n",
    "host = c['database']['host']\n",
    "username = c['database']['user']\n",
    "password = c['database']['password']\n",
    "db = c['database']['database']\n",
    "\n",
    "news_api_key = c['newsAuth']['api_key']\n",
    "tiktok_id = c['tiktokAuth']['s_v_web_id']\n",
    "# twitter_api_key = c['twitterAuth']['api_key']\n",
    "\n",
    "access_token = c['twitterAuth']['access_token']\n",
    "access_token_secret = c['twitterAuth']['access_token_secret']\n",
    "consumer_key = c['twitterAuth']['consumer_key']\n",
    "consumer_secret = c['twitterAuth']['consumer_secret']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "create Database class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataBase():\n",
    "    def __init__(self, host_name, user_name, user_password):\n",
    "        self.host_name = host_name\n",
    "        self.user_name = user_name\n",
    "        self.user_password = user_password\n",
    "\n",
    "    def create_server_connection(self):\n",
    "        self.connection = None\n",
    "        try:\n",
    "            self.connection = psycopg2.connect(\n",
    "                host=self.host_name,\n",
    "                user=self.user_name,\n",
    "                password=self.user_password\n",
    "            )\n",
    "            logging.info(\"Database connection successful\")\n",
    "        except Error as err:\n",
    "            logging.error(f\"Error: '{err}'\")\n",
    "\n",
    "        return self.connection\n",
    "\n",
    "\n",
    "    def create_database(self, connection, query):\n",
    "            self.connection = connection\n",
    "            cursor = connection.cursor()\n",
    "            try:\n",
    "                cursor.execute(query)\n",
    "                logging.info(\"Database created successfully\")\n",
    "            except Error as err:\n",
    "                logging.error(f\"Error: '{err}'\")\n",
    "\n",
    "\n",
    "    def create_db_connection(self, db_name):\n",
    "            self.db_name = db_name\n",
    "            self.connection = None\n",
    "            try:\n",
    "                self.connection = psycopg2.connect(\n",
    "                    host=self.host_name,\n",
    "                    user=self.user_name,\n",
    "                    password=self.user_password,\n",
    "                    database=self.db_name\n",
    "                )\n",
    "                # cursor = connection.cursor()\n",
    "                logging.info(\"PostgreSQL Database connection successful\")\n",
    "            except Error as err:\n",
    "                logging.error(f\"Error: '{err}'\")\n",
    "\n",
    "            return self.connection\n",
    "\n",
    "    # @Timer(name='Query Execution') #*TODO fix __enter__ attribute error\n",
    "    def execute_query(self, connection, query):\n",
    "            self.connection = connection\n",
    "            cursor = connection.cursor()\n",
    "            try:\n",
    "                cursor.execute(query)\n",
    "                self.connection.commit()\n",
    "                logging.info(\"Query successful\")\n",
    "            except Error as err:\n",
    "                print(f\"Error: '{err}'\")\n",
    "    \n",
    "    def read_query(self, connection, query):\n",
    "        self.connection = connection\n",
    "        cursor = self.connection.cursor()\n",
    "        result = None\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "            return result\n",
    "        except Error as err:\n",
    "            logging.error(f\"Error: '{err}'\")\n",
    "    \n",
    "\n",
    "    @Timer(name='Mogrify')\n",
    "    def execute_mogrify(self, conn, df, table):\n",
    "        \"\"\"\n",
    "        Using cursor.mogrify() to build the bulk insert query\n",
    "        then cursor.execute() to execute the query\n",
    "        \"\"\"\n",
    "        self.connection = conn\n",
    "        # Create a list of tupples from the dataframe values\n",
    "        tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    \n",
    "        # Comma-separated dataframe columns\n",
    "        cols = ','.join(list(df.columns))\n",
    "    \n",
    "        # SQL query to execute\n",
    "        cursor = conn.cursor()\n",
    "        values = [cursor.mogrify(\"(%s,%s,%s,%s)\", tup).decode('utf8')\n",
    "                for tup in tuples]\n",
    "        # if not publishedAt, delete record\n",
    "        query = \"INSERT INTO %s(%s) VALUES\" % (table, cols) + \",\".join(values)\n",
    "\n",
    "        try:\n",
    "            cursor.execute(query, tuples)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            logging.error(\"Error: %s\" % error)\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return 1\n",
    "        logging.info(\"execute_mogrify() done\")\n",
    "        cursor.close()\n",
    "        conn.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Variables for SQL queries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create db \n",
    "create_database_query = \"\"\"\n",
    "        CREATE DATABASE IF NOT EXISTS sm_news;\n",
    "    \"\"\"\n",
    "# create necessary tables\n",
    "create_article_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS articles (\n",
    "        publishedAt DATE,\n",
    "        title VARCHAR PRIMARY KEY,\n",
    "        author VARCHAR,\n",
    "        url TEXT\n",
    "        );\n",
    "    \"\"\"\n",
    "create_article_table_index = \"\"\"\n",
    "    CREATE INDEX index\n",
    "        ON articles(publishedAt,\n",
    "            title\n",
    "        );\n",
    "    \"\"\"\n",
    "create_article_text_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS article_text (\n",
    "        title VARCHAR PRIMARY KEY,\n",
    "        article_text TEXT\n",
    "        );\n",
    "    \"\"\"\n",
    "create_political_event_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS event (\n",
    "        eventID ID PRIMARY KEY,\n",
    "        startDate DATE,\n",
    "        name VARCHAR NOT NULL,\n",
    "        description VARCHAR NOT NULL,\n",
    "        keyWords VARCHAR\n",
    "        );\n",
    " \"\"\"\n",
    "create_tweets_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tweets (\n",
    "        tweet_id INT PRIMARY KEY,\n",
    "        publishedAt DATE NOT NULL,\n",
    "        userID VARCHAR NOT NULL,\n",
    "        tweet VARCHAR NOT NULL,\n",
    "        location VARCHAR NOT NULL, \n",
    "        tags VARCHAR NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "create_tiktoks_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tiktoks (\n",
    "        postID INT PRIMARY KEY,\n",
    "        createTime DATE NOT NULL,\n",
    "        userID INT NOT NULL,\n",
    "        description VARCHAR NOT NULL,\n",
    "        musicID INT NOT NULL,\n",
    "        soundID INT NOT NULL,\n",
    "        tags VARCHAR NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "create_tiktok_sounds_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tiktok_sounds (\n",
    "        soundID INT PRIMARY KEY,\n",
    "        soundTitle VARCHAR,\n",
    "        isOriginal BOOLEAN\n",
    "        );\n",
    "    \"\"\"\n",
    "create_tiktok_music_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tiktok_music (\n",
    "        songID INT PRIMARY KEY,\n",
    "        songTitle VARCHAR NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_tiktok_stats_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tiktok_stats (\n",
    "        postID INT PRIMARY KEY,\n",
    "        shareCount INT,\n",
    "        commentCount INT,\n",
    "        playCount INT,\n",
    "        diggCount INT\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_tiktok_tags_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tiktok_tags (\n",
    "        tagID INT PRIMARY KEY,\n",
    "        tag_name VARCHAR NOT NULL \n",
    "        );\n",
    "    \"\"\"\n",
    "create_users_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        userID INT PRIMARY KEY,\n",
    "        username VARCHAR NOT NULL,\n",
    "        user_bio VARCHAR NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "delete_bad_data = \"\"\"\n",
    "    DELETE FROM articles\n",
    "        WHERE publishedAt IS NULL;\n",
    "    \"\"\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "postgres_db = DataBase(host, username, password)\n",
    "\n",
    "# connect to server\n",
    "postgres_server = postgres_db.create_server_connection()\n",
    "\n",
    "# connect to social media news db\n",
    "connection = postgres_db.create_db_connection(db)\n",
    "\n",
    "# execute defined queries to create db tables if needed\n",
    "try:\n",
    "    postgres_db.execute_query(connection, create_article_table) # TODO fix attribute error __enter__ for Timer wrapper\n",
    "    postgres_db.execute_query(connection, create_article_text_table)\n",
    "    postgres_db.execute_query(connection, create_tweets_table)\n",
    "    postgres_db.execute_query(connection, create_political_event_table)\n",
    "    postgres_db.execute_query(connection, create_users_table)\n",
    "    postgres_db.execute_query(connection, create_tiktok_sounds_table)\n",
    "    postgres_db.execute_query(connection, create_tiktok_music_table)\n",
    "    postgres_db.execute_query(connection, create_tiktok_stats_table)\n",
    "    postgres_db.execute_query(connection, create_tiktok_tags_table)\n",
    "    postgres_db.execute_query(connection, create_tiktoks_table)\n",
    "except (ConnectionError) as e:\n",
    "    logging.error({e}, 'Check SQL create queries')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add foreign keys\n",
    "alter_tiktoks_table = \"\"\"\n",
    "    ALTER TABLE tiktoks\n",
    "    ADD FOREIGN KEY(musicID) REFERENCES tiktok_music(songID),\n",
    "    ADD FOREIGN KEY(soundID) REFERENCES tiktok_sounds(soundID),\n",
    "    ADD FOREIGN KEY(userID) REFERENCES users(userID)\n",
    "    ON DELETE SET NULL;\n",
    "\"\"\"\n",
    "alter_tiktok_stats_table = \"\"\"\n",
    "    ALTER TABLE tiktok_stats\n",
    "    ADD FOREIGN KEY(postID) REFERENCES tiktoks(postID)\n",
    "    ON DELETE SET NULL;\n",
    "\"\"\"\n",
    "try:\n",
    "    postgres_db.execute_query(connection, alter_tiktoks_table)\n",
    "    postgres_db.execute_query(connection, alter_tiktok_stats_table)\n",
    "except (ConnectionError) as e:\n",
    "    logging.error({e}, 'Check SQL alteration queries')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Find Top News by Day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create News class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class News():\n",
    "    \"\"\"Extract keywords from  news articles to use as search values for TikTok & Twitter posts relating to the political event of interest. \"\"\"\n",
    "\n",
    "    def __init__(self, api_key, logger=logging):\n",
    "        self.api_key = api_key\n",
    "        self.logger = logging.basicConfig(filename='news.log', filemode='w',\n",
    "                    format=f'%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    def request_pop_news(self, params={\n",
    "        'q': ['politics' or 'political' or 'law' or 'legal' or 'policy'],\n",
    "        'from': {date.today() - timedelta(days=3)},\n",
    "        'to': {date.today},\n",
    "        'language': 'en',\n",
    "        'sort_by': 'popularity'\n",
    "    }):\n",
    "        pop_news = []\n",
    "        self.params = params\n",
    "\n",
    "        headers = {\n",
    "            'X-Api-Key': self.api_key,\n",
    "            # get_random_ua for Chrome\n",
    "            'user-agent': get_random_ua('Chrome')\n",
    "        }\n",
    "\n",
    "        url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "        # response as JSON dict\n",
    "        self.response = requests.get(url, params=self.params, headers=headers).json()\n",
    "\n",
    "        with open('pop_news.json', 'w') as f:\n",
    "            # write results to JSON file\n",
    "            json.dump(self.response, f)\n",
    "\n",
    "        with open('pop_news.json', 'r') as file:\n",
    "            # create Python list object from JSON\n",
    "            pop_news_json = file.read().split(\"\\n\")\n",
    "\n",
    "            for story in pop_news_json:\n",
    "                pop_obj = json.loads(story)\n",
    "\n",
    "                if 'title' in pop_obj:\n",
    "                    pop_obj['title'] = pop_obj['articles']['title']\n",
    "                if 'author' in pop_obj:\n",
    "                    pop_obj['author'] = pop_obj['articles']['author']\n",
    "                if 'url' in pop_obj:\n",
    "                    pop_obj['url'] = pop_obj['articles']['url']\n",
    "                if 'publishedAt' in pop_obj:\n",
    "                    pop_obj['publishedAt'] = pop_obj['articles']['publishedAt']\n",
    "\n",
    "                # add info to pop_news dict\n",
    "                pop_news.append(pop_obj)\n",
    "\n",
    "        return pop_news\n",
    "\n",
    "    def get_top_headlines(self, params={\n",
    "        \"language\": \"en\",\n",
    "        \"country\": \"us\"\n",
    "    }):\n",
    "\n",
    "        top_headlines = []\n",
    "        self.params = params\n",
    "\n",
    "        headers = {\n",
    "            \"X-Api-Key\": news_api_key,\n",
    "            \"user-agent\": get_random_ua('Chrome')\n",
    "        }\n",
    "        url = \"https://newsapi.org/v2/top-headlines\"\n",
    "\n",
    "        self.response = requests.get(\n",
    "            url, params=self.params, headers=headers).json()  # response JSON dict\n",
    "\n",
    "        with open(\"top_headlines.json\", \"w\") as f:\n",
    "            # write results to JSON file\n",
    "            json.dump(self.response, f)\n",
    "\n",
    "        with open(\"top_headlines.json\", \"r\") as file:\n",
    "            # create Python object from JSON\n",
    "            top_headlines_json = file.read().split(\"\\n\")\n",
    "\n",
    "            for story in top_headlines_json:\n",
    "                story_obj = json.loads(story)\n",
    "\n",
    "                if 'title' in story_obj:\n",
    "                    story_obj[\"title\"] = story_obj[\"articles\"][\"title\"]\n",
    "                if 'author' in story_obj:\n",
    "                    story_obj[\"author\"] = story_obj[\"articles\"][\"author\"]\n",
    "                if 'url' in story_obj:\n",
    "                    story_obj[\"url\"] = story_obj[\"articles\"][\"url\"]\n",
    "                if 'publishedAt' in story_obj:\n",
    "                    story_obj[\"publishedAt\"] = story_obj[\"articles\"][\"publishedAt\"]\n",
    "\n",
    "                # add info to top_headlines list/dict\n",
    "                top_headlines.append(story_obj)\n",
    "\n",
    "        return top_headlines\n",
    "\n",
    "    # put all news together\n",
    "    def get_all_news(self):\n",
    "        \"\"\"Combines top headlines and popular news into one Pandas DataFrame.\"\"\"\n",
    "        top_headlines = self.get_top_headlines()\n",
    "        pop_news = self.request_pop_news()\n",
    "\n",
    "        # noramlize nested JSON\n",
    "        pop_news = pd.json_normalize(pop_news, record_path=['articles'])\n",
    "        top_headlines = pd.json_normalize(top_headlines, record_path=['articles'])\n",
    "        all_news = top_headlines.append(pop_news)\n",
    "\n",
    "        # create dataframe from combined news list\n",
    "        self.all_news_df = pd.DataFrame(\n",
    "            all_news, columns=['title', 'author', 'url', 'publishedAt', \"text\"])\n",
    "        self.all_news_df.drop_duplicates()\n",
    "\n",
    "        # convert to datetime\n",
    "        self.all_news_df['publishedAt'] = self.all_news_df['publishedAt'].map(\n",
    "            lambda row: datetime.strptime(str(row), \"%Y-%m-%dT%H:%M:%SZ\") if pd.notnull(row) else row)\n",
    "\n",
    "        # set index to publishing time, inplace to apply to same df instead of copy or view\n",
    "        self.all_news_df.set_index('publishedAt', inplace=True)\n",
    "        \n",
    "        # apply .get_article_text() to text column of df\n",
    "        self.all_news_df[\"text\"] = self.all_news_df[\"url\"].apply(self.get_article_text)\n",
    "        \n",
    "        \n",
    "        return self.all_news_df\n",
    "\n",
    "    \n",
    "    def get_article_text(self, url): \n",
    "        \"\"\"Clean & process news article text to prepare for keyword extraction\"\"\"\n",
    "        \n",
    "        contractions_dict = {\"'s\": \" is\", \"n't\": \" not\", \"'m\": \" am\", \"'ll\": \" will\",\n",
    "                     \"'d\": \" would\", \"'ve\": \" have\", \"'re\": \" are\"}\n",
    "        symbols_list = ['&', '+', '-', '/', '|', '$', '%', ':', '(', ')', '?']\n",
    "        \n",
    "        # request\n",
    "        r = requests.get(url)\n",
    "        html = r.text\n",
    "        soup = BeautifulSoup(html)\n",
    "        a_text = soup.get_text()\n",
    "\n",
    "        # remove newline characters\n",
    "        a_text = a_text.strip()\n",
    "        # split joined words\n",
    "        a_text = \" \".join([s for s in re.split(\"([A-Z][a-z]+[^A-Z]*)\", a_text) if s])\n",
    "        # remove mentions\n",
    "        a_text = re.sub(\"@\\S+\", \" \", a_text)\n",
    "        # remove URLs\n",
    "        a_text = re.sub(\"https*\\S+\", \" \", a_text)\n",
    "        # remove hashtags\n",
    "        a_text = re.sub(\"#\\S+\", \" \", a_text)\n",
    "        # remove unicode characters\n",
    "        a_text = a_text.encode('ascii', 'ignore').decode()\n",
    "        # replace contractions\n",
    "        for key, value in contractions_dict.items():\n",
    "            if key in a_text:\n",
    "                a_text = a_text.replace(key, value)\n",
    "        # remove symbols and punctuation\n",
    "        for i in symbols_list:\n",
    "            if i in a_text:\n",
    "                a_text = a_text.replace(i, '')\n",
    "\n",
    "        # make lowercase\n",
    "        a_text = a_text.lower()\n",
    "        a_text = re.sub(r'\\w*\\d+\\w*', '', a_text)\n",
    "\n",
    "        return a_text\n",
    "\n",
    "    def keyword_extraction(self, text):\n",
    "        \"\"\"Determine weight of important words in articles and add to articles_text table\n",
    "        using TF-IDF ranking\"\"\"\n",
    "\n",
    "        # make sure text is in string format for parsing\n",
    "        text = str(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # find total words in document for calculating Term Frequency (TF)\n",
    "        total_words = text.split()\n",
    "        total_word_length = len(total_words)\n",
    "\n",
    "        # find total number of sentences for calculating Inverse Document Frequency\n",
    "        total_sentences = tokenize.sent_tokenize(text)\n",
    "        total_sent_len = len(total_sentences)\n",
    "\n",
    "        # calculate TF for each word\n",
    "        tf_score = {}\n",
    "        for each_word in total_words:\n",
    "            each_word = each_word.replace('.', '')\n",
    "            if each_word not in stop_words and len(each_word) > 3:\n",
    "                if each_word in tf_score:\n",
    "                    tf_score[each_word] += 1\n",
    "                else:\n",
    "                    tf_score[each_word] = 1\n",
    "\n",
    "        # Divide by total_word_length for each dictionary element\n",
    "        tf_score.update((x, y/int(total_word_length))\n",
    "                        for x, y in tf_score.items())  # TODO test - ZeroError\n",
    "\n",
    "        #calculate IDF for each word\n",
    "        idf_score = {}\n",
    "        for each_word in total_words:\n",
    "            each_word = each_word.replace('.', '')\n",
    "            if each_word not in stop_words and len(each_word) > 3:\n",
    "                if each_word in idf_score:\n",
    "                    idf_score[each_word] = self.check_sent(each_word, total_sentences)\n",
    "                else:\n",
    "                    idf_score[each_word] = 1\n",
    "\n",
    "        # Performing a log and divide\n",
    "        idf_score.update((x, math.log(int(total_sent_len)/y))\n",
    "                        for x, y in idf_score.items())\n",
    "\n",
    "        # Calculate IDF * TF for each word\n",
    "        tf_idf_score = {key: tf_score[key] *\n",
    "                        idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "\n",
    "        return tf_idf_score\n",
    "\n",
    "    def check_sent(self, word, sentences):\n",
    "        \"\"\"Check if word is present in sentence list for calculating IDF (Inverse Document Frequency)\"\"\"\n",
    "        final = [all([w in x for w in word]) for x in sentences]\n",
    "        sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    \n",
    "        return int(len(sent_len))\n",
    "\n",
    "    def get_top_n(self, dict_elem, n):\n",
    "        \"\"\"Calculate most important keywords in text of interest\"\"\"\n",
    "        result = dict(sorted(dict_elem.items(),\n",
    "                     key=itemgetter(1), reverse=True)[:n])\n",
    "        result = result.keys()\n",
    "\n",
    "        return result\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Parse Titles & Articles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# instantiate News class\n",
    "news = News(news_api_key)\n",
    "# get all news - takes about 30 seconds\n",
    "news.get_all_news()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                 title  \\\n",
       "publishedAt                                                              \n",
       "2021-08-27 22:37:52  The 13 U.S. service members killed in the Kabu...   \n",
       "2021-08-27 22:21:00  RFK assassin Sirhan Sirhan gets parole on 16th...   \n",
       "2021-08-27 21:31:00  Lauri Markkanen traded to the Cleveland Cavali...   \n",
       "2021-08-27 21:25:00  2021 Fantasy Football Draft Prep: Best ADP val...   \n",
       "2021-08-27 20:50:00  You Can Use Windows 11 on Unsupported Hardware...   \n",
       "2021-08-27 20:10:07      Florida starts turning on DeSantis - POLITICO   \n",
       "2021-08-27 20:03:00  Unvaccinated, unmasked teacher infected more t...   \n",
       "2021-08-27 19:40:09  U.S. intelligence agencies split on Covid-19 o...   \n",
       "2021-08-27 19:37:07  Map: Tracking Hurricane Ida's Path - The New Y...   \n",
       "2021-08-27 19:36:29  Does Delta Variant Pose Less Risk With 6 Feet ...   \n",
       "2021-08-27 19:16:40  Fed Chair Powell says inflation surge will be ...   \n",
       "2021-08-27 19:13:45  House Jan. 6 committee seeks information from ...   \n",
       "2021-08-27 19:10:00  Texas House approves GOP voting restrictions b...   \n",
       "2021-08-27 18:57:04  Fox Analyst Jay Glazer Takes Victory Lap as Cr...   \n",
       "2021-08-27 18:53:13  Kim Kardashian and Kanye West Reenact Their We...   \n",
       "2021-08-27 18:34:30  Female hummingbirds avoid sexual harassment by...   \n",
       "2021-08-27 18:34:12  Peloton says it’s subject to DOJ, DHS, and SEC...   \n",
       "2021-08-27 18:30:48  How Blue Origin, SpaceX, Virgin Galactic space...   \n",
       "2021-08-27 18:28:47  Louisville Cardinals suspend men's basketball ...   \n",
       "2021-08-27 18:15:52  T-Mobile CEO apologizes for data breach, annou...   \n",
       "2021-08-24 16:55:58  Gavin Newsom’s Recall Election Divides Silicon...   \n",
       "2021-08-24 13:12:20  House Democrats Struggle for Votes to Pass $3....   \n",
       "2021-08-27 09:00:14  Justice Breyer on Retirement and the Role of P...   \n",
       "2021-08-26 14:51:45                                 Politics this week   \n",
       "2021-08-24 15:56:00  Starvation stalks Afghanistan, politics must b...   \n",
       "2021-08-26 22:30:22  Analysis: President DeSantis? Florida voters s...   \n",
       "2021-08-24 15:28:40  Paralympics opening ceremony: pandemic, politi...   \n",
       "2021-08-25 01:26:00  Hong Kong lawyers attacked by pro-Beijing medi...   \n",
       "2021-08-25 17:36:32  After Mark Sanford lost a GOP House primary to...   \n",
       "2021-08-24 14:01:16  As ISS Enters Its Final Years, Politics Take C...   \n",
       "2021-08-27 05:00:09  The Greens in the UK are on the brink of power...   \n",
       "2021-08-25 18:13:08  Joe Manchin Faces Protests from the Left at Ho...   \n",
       "2021-08-25 23:09:19  Kenya's Deputy President Ruto campaigns for 'H...   \n",
       "2021-08-26 17:13:19  Only bold policies will win back Labour voters...   \n",
       "2021-08-24 17:02:20  A California judge just struck down Prop 22: N...   \n",
       "2021-08-24 13:12:36  Kathy Hochul sworn in as first female governor...   \n",
       "2021-08-27 03:41:37  The White House says it is 'not a day for poli...   \n",
       "2021-08-26 19:54:30  Michel Barnier to run in French presidential e...   \n",
       "2021-08-25 18:08:37  Capitol attack committee issues sweeping reque...   \n",
       "2021-08-26 14:00:00  How COVID, Inequality and Politics Make a Vici...   \n",
       "\n",
       "                                                                author  \\\n",
       "publishedAt                                                              \n",
       "2021-08-27 22:37:52  Shawn Boburg, Meagan Flynn, Alex Horton, Ellen...   \n",
       "2021-08-27 22:21:00                Ray Sanchez and Cheri Mossburg, CNN   \n",
       "2021-08-27 21:31:00                                      Bryan Fonseca   \n",
       "2021-08-27 21:25:00                                                      \n",
       "2021-08-27 20:50:00                                       Florence Ion   \n",
       "2021-08-27 20:10:07                                         MATT DIXON   \n",
       "2021-08-27 20:03:00                                    Maggie Fox, CNN   \n",
       "2021-08-27 19:40:09                                      Amanda Macias   \n",
       "2021-08-27 19:37:07                                      Matthew Bloch   \n",
       "2021-08-27 19:36:29                                               None   \n",
       "2021-08-27 19:16:40                                     Kelsey Ramirez   \n",
       "2021-08-27 19:13:45                         Dave Clarke, Tom Hamburger   \n",
       "2021-08-27 19:10:00             Eric Bradner and Dianne Gallagher, CNN   \n",
       "2021-08-27 18:57:04                                    Michael Shapiro   \n",
       "2021-08-27 18:53:13                                     Janelle Okwodu   \n",
       "2021-08-27 18:34:30                                      Hannah Sparks   \n",
       "2021-08-27 18:34:12                                     Mitchell Clark   \n",
       "2021-08-27 18:30:48                                       Charlie Wood   \n",
       "2021-08-27 18:28:47                                     Mark Schlabach   \n",
       "2021-08-27 18:15:52  https://www.engadget.com/about/editors/igor-bo...   \n",
       "2021-08-24 16:55:58                                     Arielle Pardes   \n",
       "2021-08-24 13:12:20                                 The New York Times   \n",
       "2021-08-27 09:00:14                                        Adam Liptak   \n",
       "2021-08-26 14:51:45                                      The Economist   \n",
       "2021-08-24 15:56:00                                            Reuters   \n",
       "2021-08-26 22:30:22    Analysis by Chris Cillizza, CNN Editor-at-large   \n",
       "2021-08-24 15:28:40             Paul MacInnes at Tokyo Olympic Stadium   \n",
       "2021-08-25 01:26:00                                            Reuters   \n",
       "2021-08-25 17:36:32               insider@insider.com (John L. Dorman)   \n",
       "2021-08-24 14:01:16                                          Tom Nardi   \n",
       "2021-08-27 05:00:09                                       Andy Beckett   \n",
       "2021-08-25 18:13:08                                     Philip Elliott   \n",
       "2021-08-25 23:09:19                   https://www.facebook.com/bbcnews   \n",
       "2021-08-26 17:13:19                                            Letters   \n",
       "2021-08-24 17:02:20                                      Annie Siebert   \n",
       "2021-08-24 13:12:36                          Ed Pilkington in New York   \n",
       "2021-08-27 03:41:37              cteh@businessinsider.com (Cheryl Teh)   \n",
       "2021-08-26 19:54:30                               Agence France-Presse   \n",
       "2021-08-25 18:08:37                                          Maya Yang   \n",
       "2021-08-26 14:00:00              Emily Mendenhall, Clarence C. Gravlee   \n",
       "\n",
       "                                                                   url  \\\n",
       "publishedAt                                                              \n",
       "2021-08-27 22:37:52  https://www.washingtonpost.com/national-securi...   \n",
       "2021-08-27 22:21:00  https://www.cnn.com/2021/08/27/us/sirhan-sirha...   \n",
       "2021-08-27 21:31:00  https://deadspin.com/lauri-markkanen-trade-mea...   \n",
       "2021-08-27 21:25:00  https://www.cbssports.com/fantasy/football/new...   \n",
       "2021-08-27 20:50:00  https://gizmodo.com/you-can-use-windows-11-on-...   \n",
       "2021-08-27 20:10:07  https://www.politico.com/states/florida/story/...   \n",
       "2021-08-27 20:03:00  https://www.cnn.com/2021/08/27/health/teacher-...   \n",
       "2021-08-27 19:40:09  https://www.cnbc.com/2021/08/27/covid-origin-r...   \n",
       "2021-08-27 19:37:07  https://www.nytimes.com/interactive/2021/us/hu...   \n",
       "2021-08-27 19:36:29  https://www.npr.org/sections/goatsandsoda/2021...   \n",
       "2021-08-27 19:16:40  https://www.foxbusiness.com/personal-finance/f...   \n",
       "2021-08-27 19:13:45  https://www.washingtonpost.com/politics/januar...   \n",
       "2021-08-27 19:10:00  https://www.cnn.com/2021/08/27/politics/texas-...   \n",
       "2021-08-27 18:57:04  https://www.si.com/soccer/2021/08/27/jay-glaze...   \n",
       "2021-08-27 18:53:13  https://www.vogue.com/article/kanye-west-kim-k...   \n",
       "2021-08-27 18:34:30  https://nypost.com/2021/08/27/female-hummingbi...   \n",
       "2021-08-27 18:34:12  https://www.theverge.com/2021/8/27/22644743/pe...   \n",
       "2021-08-27 18:30:48  https://www.cnbc.com/2021/08/27/how-blue-origi...   \n",
       "2021-08-27 18:28:47  https://www.espn.com/mens-college-basketball/s...   \n",
       "2021-08-27 18:15:52  https://www.engadget.com/t-mobile-mandiant-sec...   \n",
       "2021-08-24 16:55:58  https://www.wired.com/story/gavin-newsom-recal...   \n",
       "2021-08-24 13:12:20  https://www.nytimes.com/live/2021/08/24/us/bid...   \n",
       "2021-08-27 09:00:14  https://www.nytimes.com/2021/08/27/us/politics...   \n",
       "2021-08-26 14:51:45  https://www.economist.com/the-world-this-week/...   \n",
       "2021-08-24 15:56:00  https://www.reuters.com/world/asia-pacific/sta...   \n",
       "2021-08-26 22:30:22  https://www.cnn.com/2021/08/26/politics/desant...   \n",
       "2021-08-24 15:28:40  https://amp.theguardian.com/sport/2021/aug/24/...   \n",
       "2021-08-25 01:26:00  https://www.reuters.com/world/china/hong-kong-...   \n",
       "2021-08-25 17:36:32  https://www.businessinsider.com/mark-sanford-r...   \n",
       "2021-08-24 14:01:16  https://hackaday.com/2021/08/24/as-iss-enters-...   \n",
       "2021-08-27 05:00:09  https://amp.theguardian.com/commentisfree/2021...   \n",
       "2021-08-25 18:13:08  https://time.com/6092770/joe-manchin-william-b...   \n",
       "2021-08-25 23:09:19   https://www.bbc.co.uk/news/world-africa-58246207   \n",
       "2021-08-26 17:13:19  https://amp.theguardian.com/politics/2021/aug/...   \n",
       "2021-08-24 17:02:20  http://techcrunch.com/2021/08/24/a-california-...   \n",
       "2021-08-24 13:12:36  https://amp.theguardian.com/us-news/2021/aug/2...   \n",
       "2021-08-27 03:41:37  https://www.businessinsider.com/jen-psaki-not-...   \n",
       "2021-08-26 19:54:30  https://amp.theguardian.com/world/2021/aug/26/...   \n",
       "2021-08-25 18:08:37  https://amp.theguardian.com/us-news/2021/aug/2...   \n",
       "2021-08-26 14:00:00  https://www.scientificamerican.com/article/how...   \n",
       "\n",
       "                                                                  text  \\\n",
       "publishedAt                                                              \n",
       "2021-08-27 22:37:52  the   u.s. service members killed in the  kabu...   \n",
       "2021-08-27 22:21:00  sirhan  sirhan  sen.  robert  f.  kennedy is c...   \n",
       "2021-08-27 21:31:00  lauri  markkanen traded to the  cleveland  cav...   \n",
       "2021-08-27 21:25:00    fantasy  football  draft  prep  best  adp va...   \n",
       "2021-08-27 20:50:00  you  can  use  windows  on  unsupported  hardw...   \n",
       "2021-08-27 20:10:07  florida starts turning on  de santis\\n\\n\\n\\n\\n...   \n",
       "2021-08-27 20:03:00  unvaccinated, unmasked teacher infected more t...   \n",
       "2021-08-27 19:40:09   report  u.s. intelligence agencies are divide...   \n",
       "2021-08-27 19:37:07  map  tracking  hurricane  idas  path   the  ne...   \n",
       "2021-08-27 19:36:29  does  delta  variant  pose  less  risk  with  ...   \n",
       "2021-08-27 19:16:40  fed  chair  powell says inflation surge will b...   \n",
       "2021-08-27 19:13:45  house  jan.  committee seeks information from ...   \n",
       "2021-08-27 19:10:00  texas  house approves  gop voting restrictions...   \n",
       "2021-08-27 18:57:04  jay  glazer celebrates  cristiano  ronaldo joi...   \n",
       "2021-08-27 18:53:13  kim  kardashian and  kanye  west  reenact  the...   \n",
       "2021-08-27 18:34:30  female hummingbirds avoid sexual harassment by...   \n",
       "2021-08-27 18:34:12  peloton says its subject to  doj, dhs, and sec...   \n",
       "2021-08-27 18:30:48  how  blue  origin,  space x,  virgin  galactic...   \n",
       "2021-08-27 18:28:47  louisville  cardinals suspend men is basketbal...   \n",
       "2021-08-27 18:15:52  t mobile  ceo apologizes for data breach, anno...   \n",
       "2021-08-24 16:55:58  gavin  newsoms  recall  election  divides  sil...   \n",
       "2021-08-24 13:12:20  house narrowly passes . trillion budget bluepr...   \n",
       "2021-08-27 09:00:14  justice  breyer on  retirement and the  role o...   \n",
       "2021-08-26 14:51:45  politics this week   the  economist the  econo...   \n",
       "2021-08-24 15:56:00  starvation stalks  afghanistan, politics must ...   \n",
       "2021-08-26 22:30:22  president  de santis  florida voters say 'no.'...   \n",
       "2021-08-24 15:28:40  paralympics opening ceremony pandemic, politic...   \n",
       "2021-08-25 01:26:00  hong  kong lawyers attacked by pro beijing med...   \n",
       "2021-08-25 17:36:32  mark  sanford  sons  said  loss to  trump back...   \n",
       "2021-08-24 14:01:16  as  iss  enters  its  final  years,  politics ...   \n",
       "2021-08-27 05:00:09  the  greens are on the brink of power  is it m...   \n",
       "2021-08-25 18:13:08  joe  manchin  faces  protests from the  left i...   \n",
       "2021-08-25 23:09:19  kenya is  deputy  president  ruto campaigns fo...   \n",
       "2021-08-26 17:13:19  only bold policies will win back  labour voter...   \n",
       "2021-08-24 17:02:20  a  california judge just struck down  prop   n...   \n",
       "2021-08-24 13:12:36  kathy  hochul sworn in as first female governo...   \n",
       "2021-08-27 03:41:37  jen  psaki  it is ' not a  day for  politics' ...   \n",
       "2021-08-26 19:54:30  michel  barnier to run in  french presidential...   \n",
       "2021-08-25 18:08:37  capitol attack committee issues sweeping reque...   \n",
       "2021-08-26 14:00:00  how  covid,  inequality and  politics  make a ...   \n",
       "\n",
       "                     keyword1  keyword2  keyword3  \n",
       "publishedAt                                        \n",
       "2021-08-27 22:37:52       NaN       NaN       NaN  \n",
       "2021-08-27 22:21:00       NaN       NaN       NaN  \n",
       "2021-08-27 21:31:00       NaN       NaN       NaN  \n",
       "2021-08-27 21:25:00       NaN       NaN       NaN  \n",
       "2021-08-27 20:50:00       NaN       NaN       NaN  \n",
       "2021-08-27 20:10:07       NaN       NaN       NaN  \n",
       "2021-08-27 20:03:00       NaN       NaN       NaN  \n",
       "2021-08-27 19:40:09       NaN       NaN       NaN  \n",
       "2021-08-27 19:37:07       NaN       NaN       NaN  \n",
       "2021-08-27 19:36:29       NaN       NaN       NaN  \n",
       "2021-08-27 19:16:40       NaN       NaN       NaN  \n",
       "2021-08-27 19:13:45       NaN       NaN       NaN  \n",
       "2021-08-27 19:10:00       NaN       NaN       NaN  \n",
       "2021-08-27 18:57:04       NaN       NaN       NaN  \n",
       "2021-08-27 18:53:13       NaN       NaN       NaN  \n",
       "2021-08-27 18:34:30       NaN       NaN       NaN  \n",
       "2021-08-27 18:34:12       NaN       NaN       NaN  \n",
       "2021-08-27 18:30:48       NaN       NaN       NaN  \n",
       "2021-08-27 18:28:47       NaN       NaN       NaN  \n",
       "2021-08-27 18:15:52       NaN       NaN       NaN  \n",
       "2021-08-24 16:55:58       NaN       NaN       NaN  \n",
       "2021-08-24 13:12:20       NaN       NaN       NaN  \n",
       "2021-08-27 09:00:14       NaN       NaN       NaN  \n",
       "2021-08-26 14:51:45       NaN       NaN       NaN  \n",
       "2021-08-24 15:56:00       NaN       NaN       NaN  \n",
       "2021-08-26 22:30:22       NaN       NaN       NaN  \n",
       "2021-08-24 15:28:40       NaN       NaN       NaN  \n",
       "2021-08-25 01:26:00       NaN       NaN       NaN  \n",
       "2021-08-25 17:36:32       NaN       NaN       NaN  \n",
       "2021-08-24 14:01:16       NaN       NaN       NaN  \n",
       "2021-08-27 05:00:09       NaN       NaN       NaN  \n",
       "2021-08-25 18:13:08       NaN       NaN       NaN  \n",
       "2021-08-25 23:09:19       NaN       NaN       NaN  \n",
       "2021-08-26 17:13:19       NaN       NaN       NaN  \n",
       "2021-08-24 17:02:20       NaN       NaN       NaN  \n",
       "2021-08-24 13:12:36       NaN       NaN       NaN  \n",
       "2021-08-27 03:41:37       NaN       NaN       NaN  \n",
       "2021-08-26 19:54:30       NaN       NaN       NaN  \n",
       "2021-08-25 18:08:37       NaN       NaN       NaN  \n",
       "2021-08-26 14:00:00       NaN       NaN       NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>keyword1</th>\n",
       "      <th>keyword2</th>\n",
       "      <th>keyword3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publishedAt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-27 22:37:52</th>\n",
       "      <td>The 13 U.S. service members killed in the Kabu...</td>\n",
       "      <td>Shawn Boburg, Meagan Flynn, Alex Horton, Ellen...</td>\n",
       "      <td>https://www.washingtonpost.com/national-securi...</td>\n",
       "      <td>the   u.s. service members killed in the  kabu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 22:21:00</th>\n",
       "      <td>RFK assassin Sirhan Sirhan gets parole on 16th...</td>\n",
       "      <td>Ray Sanchez and Cheri Mossburg, CNN</td>\n",
       "      <td>https://www.cnn.com/2021/08/27/us/sirhan-sirha...</td>\n",
       "      <td>sirhan  sirhan  sen.  robert  f.  kennedy is c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 21:31:00</th>\n",
       "      <td>Lauri Markkanen traded to the Cleveland Cavali...</td>\n",
       "      <td>Bryan Fonseca</td>\n",
       "      <td>https://deadspin.com/lauri-markkanen-trade-mea...</td>\n",
       "      <td>lauri  markkanen traded to the  cleveland  cav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 21:25:00</th>\n",
       "      <td>2021 Fantasy Football Draft Prep: Best ADP val...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.cbssports.com/fantasy/football/new...</td>\n",
       "      <td>fantasy  football  draft  prep  best  adp va...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 20:50:00</th>\n",
       "      <td>You Can Use Windows 11 on Unsupported Hardware...</td>\n",
       "      <td>Florence Ion</td>\n",
       "      <td>https://gizmodo.com/you-can-use-windows-11-on-...</td>\n",
       "      <td>you  can  use  windows  on  unsupported  hardw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 20:10:07</th>\n",
       "      <td>Florida starts turning on DeSantis - POLITICO</td>\n",
       "      <td>MATT DIXON</td>\n",
       "      <td>https://www.politico.com/states/florida/story/...</td>\n",
       "      <td>florida starts turning on  de santis\\n\\n\\n\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 20:03:00</th>\n",
       "      <td>Unvaccinated, unmasked teacher infected more t...</td>\n",
       "      <td>Maggie Fox, CNN</td>\n",
       "      <td>https://www.cnn.com/2021/08/27/health/teacher-...</td>\n",
       "      <td>unvaccinated, unmasked teacher infected more t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:40:09</th>\n",
       "      <td>U.S. intelligence agencies split on Covid-19 o...</td>\n",
       "      <td>Amanda Macias</td>\n",
       "      <td>https://www.cnbc.com/2021/08/27/covid-origin-r...</td>\n",
       "      <td>report  u.s. intelligence agencies are divide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:37:07</th>\n",
       "      <td>Map: Tracking Hurricane Ida's Path - The New Y...</td>\n",
       "      <td>Matthew Bloch</td>\n",
       "      <td>https://www.nytimes.com/interactive/2021/us/hu...</td>\n",
       "      <td>map  tracking  hurricane  idas  path   the  ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:36:29</th>\n",
       "      <td>Does Delta Variant Pose Less Risk With 6 Feet ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.npr.org/sections/goatsandsoda/2021...</td>\n",
       "      <td>does  delta  variant  pose  less  risk  with  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:16:40</th>\n",
       "      <td>Fed Chair Powell says inflation surge will be ...</td>\n",
       "      <td>Kelsey Ramirez</td>\n",
       "      <td>https://www.foxbusiness.com/personal-finance/f...</td>\n",
       "      <td>fed  chair  powell says inflation surge will b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:13:45</th>\n",
       "      <td>House Jan. 6 committee seeks information from ...</td>\n",
       "      <td>Dave Clarke, Tom Hamburger</td>\n",
       "      <td>https://www.washingtonpost.com/politics/januar...</td>\n",
       "      <td>house  jan.  committee seeks information from ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 19:10:00</th>\n",
       "      <td>Texas House approves GOP voting restrictions b...</td>\n",
       "      <td>Eric Bradner and Dianne Gallagher, CNN</td>\n",
       "      <td>https://www.cnn.com/2021/08/27/politics/texas-...</td>\n",
       "      <td>texas  house approves  gop voting restrictions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:57:04</th>\n",
       "      <td>Fox Analyst Jay Glazer Takes Victory Lap as Cr...</td>\n",
       "      <td>Michael Shapiro</td>\n",
       "      <td>https://www.si.com/soccer/2021/08/27/jay-glaze...</td>\n",
       "      <td>jay  glazer celebrates  cristiano  ronaldo joi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:53:13</th>\n",
       "      <td>Kim Kardashian and Kanye West Reenact Their We...</td>\n",
       "      <td>Janelle Okwodu</td>\n",
       "      <td>https://www.vogue.com/article/kanye-west-kim-k...</td>\n",
       "      <td>kim  kardashian and  kanye  west  reenact  the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:34:30</th>\n",
       "      <td>Female hummingbirds avoid sexual harassment by...</td>\n",
       "      <td>Hannah Sparks</td>\n",
       "      <td>https://nypost.com/2021/08/27/female-hummingbi...</td>\n",
       "      <td>female hummingbirds avoid sexual harassment by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:34:12</th>\n",
       "      <td>Peloton says it’s subject to DOJ, DHS, and SEC...</td>\n",
       "      <td>Mitchell Clark</td>\n",
       "      <td>https://www.theverge.com/2021/8/27/22644743/pe...</td>\n",
       "      <td>peloton says its subject to  doj, dhs, and sec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:30:48</th>\n",
       "      <td>How Blue Origin, SpaceX, Virgin Galactic space...</td>\n",
       "      <td>Charlie Wood</td>\n",
       "      <td>https://www.cnbc.com/2021/08/27/how-blue-origi...</td>\n",
       "      <td>how  blue  origin,  space x,  virgin  galactic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:28:47</th>\n",
       "      <td>Louisville Cardinals suspend men's basketball ...</td>\n",
       "      <td>Mark Schlabach</td>\n",
       "      <td>https://www.espn.com/mens-college-basketball/s...</td>\n",
       "      <td>louisville  cardinals suspend men is basketbal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 18:15:52</th>\n",
       "      <td>T-Mobile CEO apologizes for data breach, annou...</td>\n",
       "      <td>https://www.engadget.com/about/editors/igor-bo...</td>\n",
       "      <td>https://www.engadget.com/t-mobile-mandiant-sec...</td>\n",
       "      <td>t mobile  ceo apologizes for data breach, anno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 16:55:58</th>\n",
       "      <td>Gavin Newsom’s Recall Election Divides Silicon...</td>\n",
       "      <td>Arielle Pardes</td>\n",
       "      <td>https://www.wired.com/story/gavin-newsom-recal...</td>\n",
       "      <td>gavin  newsoms  recall  election  divides  sil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 13:12:20</th>\n",
       "      <td>House Democrats Struggle for Votes to Pass $3....</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/live/2021/08/24/us/bid...</td>\n",
       "      <td>house narrowly passes . trillion budget bluepr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 09:00:14</th>\n",
       "      <td>Justice Breyer on Retirement and the Role of P...</td>\n",
       "      <td>Adam Liptak</td>\n",
       "      <td>https://www.nytimes.com/2021/08/27/us/politics...</td>\n",
       "      <td>justice  breyer on  retirement and the  role o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26 14:51:45</th>\n",
       "      <td>Politics this week</td>\n",
       "      <td>The Economist</td>\n",
       "      <td>https://www.economist.com/the-world-this-week/...</td>\n",
       "      <td>politics this week   the  economist the  econo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 15:56:00</th>\n",
       "      <td>Starvation stalks Afghanistan, politics must b...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/world/asia-pacific/sta...</td>\n",
       "      <td>starvation stalks  afghanistan, politics must ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26 22:30:22</th>\n",
       "      <td>Analysis: President DeSantis? Florida voters s...</td>\n",
       "      <td>Analysis by Chris Cillizza, CNN Editor-at-large</td>\n",
       "      <td>https://www.cnn.com/2021/08/26/politics/desant...</td>\n",
       "      <td>president  de santis  florida voters say 'no.'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 15:28:40</th>\n",
       "      <td>Paralympics opening ceremony: pandemic, politi...</td>\n",
       "      <td>Paul MacInnes at Tokyo Olympic Stadium</td>\n",
       "      <td>https://amp.theguardian.com/sport/2021/aug/24/...</td>\n",
       "      <td>paralympics opening ceremony pandemic, politic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25 01:26:00</th>\n",
       "      <td>Hong Kong lawyers attacked by pro-Beijing medi...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/world/china/hong-kong-...</td>\n",
       "      <td>hong  kong lawyers attacked by pro beijing med...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25 17:36:32</th>\n",
       "      <td>After Mark Sanford lost a GOP House primary to...</td>\n",
       "      <td>insider@insider.com (John L. Dorman)</td>\n",
       "      <td>https://www.businessinsider.com/mark-sanford-r...</td>\n",
       "      <td>mark  sanford  sons  said  loss to  trump back...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 14:01:16</th>\n",
       "      <td>As ISS Enters Its Final Years, Politics Take C...</td>\n",
       "      <td>Tom Nardi</td>\n",
       "      <td>https://hackaday.com/2021/08/24/as-iss-enters-...</td>\n",
       "      <td>as  iss  enters  its  final  years,  politics ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 05:00:09</th>\n",
       "      <td>The Greens in the UK are on the brink of power...</td>\n",
       "      <td>Andy Beckett</td>\n",
       "      <td>https://amp.theguardian.com/commentisfree/2021...</td>\n",
       "      <td>the  greens are on the brink of power  is it m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25 18:13:08</th>\n",
       "      <td>Joe Manchin Faces Protests from the Left at Ho...</td>\n",
       "      <td>Philip Elliott</td>\n",
       "      <td>https://time.com/6092770/joe-manchin-william-b...</td>\n",
       "      <td>joe  manchin  faces  protests from the  left i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25 23:09:19</th>\n",
       "      <td>Kenya's Deputy President Ruto campaigns for 'H...</td>\n",
       "      <td>https://www.facebook.com/bbcnews</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-africa-58246207</td>\n",
       "      <td>kenya is  deputy  president  ruto campaigns fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26 17:13:19</th>\n",
       "      <td>Only bold policies will win back Labour voters...</td>\n",
       "      <td>Letters</td>\n",
       "      <td>https://amp.theguardian.com/politics/2021/aug/...</td>\n",
       "      <td>only bold policies will win back  labour voter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 17:02:20</th>\n",
       "      <td>A California judge just struck down Prop 22: N...</td>\n",
       "      <td>Annie Siebert</td>\n",
       "      <td>http://techcrunch.com/2021/08/24/a-california-...</td>\n",
       "      <td>a  california judge just struck down  prop   n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-24 13:12:36</th>\n",
       "      <td>Kathy Hochul sworn in as first female governor...</td>\n",
       "      <td>Ed Pilkington in New York</td>\n",
       "      <td>https://amp.theguardian.com/us-news/2021/aug/2...</td>\n",
       "      <td>kathy  hochul sworn in as first female governo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-27 03:41:37</th>\n",
       "      <td>The White House says it is 'not a day for poli...</td>\n",
       "      <td>cteh@businessinsider.com (Cheryl Teh)</td>\n",
       "      <td>https://www.businessinsider.com/jen-psaki-not-...</td>\n",
       "      <td>jen  psaki  it is ' not a  day for  politics' ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26 19:54:30</th>\n",
       "      <td>Michel Barnier to run in French presidential e...</td>\n",
       "      <td>Agence France-Presse</td>\n",
       "      <td>https://amp.theguardian.com/world/2021/aug/26/...</td>\n",
       "      <td>michel  barnier to run in  french presidential...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-25 18:08:37</th>\n",
       "      <td>Capitol attack committee issues sweeping reque...</td>\n",
       "      <td>Maya Yang</td>\n",
       "      <td>https://amp.theguardian.com/us-news/2021/aug/2...</td>\n",
       "      <td>capitol attack committee issues sweeping reque...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-26 14:00:00</th>\n",
       "      <td>How COVID, Inequality and Politics Make a Vici...</td>\n",
       "      <td>Emily Mendenhall, Clarence C. Gravlee</td>\n",
       "      <td>https://www.scientificamerican.com/article/how...</td>\n",
       "      <td>how  covid,  inequality and  politics  make a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Get Important Words & Phrases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# get keywords from article text\n",
    "news.all_news_df[\"keywords\"] = news.all_news_df['text'].apply(news.keyword_extraction)\n",
    "# get top n=3 words of significance\n",
    "news.all_news_df[\"keywords\"] = news.all_news_df[\"keywords\"].apply(\n",
    "     news.get_top_n, n=3)\n",
    "\n",
    "\n",
    "print(news.all_news_df)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                 title  \\\n",
      "publishedAt                                                              \n",
      "2021-08-27 22:37:52  The 13 U.S. service members killed in the Kabu...   \n",
      "2021-08-27 22:21:00  RFK assassin Sirhan Sirhan gets parole on 16th...   \n",
      "2021-08-27 21:31:00  Lauri Markkanen traded to the Cleveland Cavali...   \n",
      "2021-08-27 21:25:00  2021 Fantasy Football Draft Prep: Best ADP val...   \n",
      "2021-08-27 20:50:00  You Can Use Windows 11 on Unsupported Hardware...   \n",
      "2021-08-27 20:10:07      Florida starts turning on DeSantis - POLITICO   \n",
      "2021-08-27 20:03:00  Unvaccinated, unmasked teacher infected more t...   \n",
      "2021-08-27 19:40:09  U.S. intelligence agencies split on Covid-19 o...   \n",
      "2021-08-27 19:37:07  Map: Tracking Hurricane Ida's Path - The New Y...   \n",
      "2021-08-27 19:36:29  Does Delta Variant Pose Less Risk With 6 Feet ...   \n",
      "2021-08-27 19:16:40  Fed Chair Powell says inflation surge will be ...   \n",
      "2021-08-27 19:13:45  House Jan. 6 committee seeks information from ...   \n",
      "2021-08-27 19:10:00  Texas House approves GOP voting restrictions b...   \n",
      "2021-08-27 18:57:04  Fox Analyst Jay Glazer Takes Victory Lap as Cr...   \n",
      "2021-08-27 18:53:13  Kim Kardashian and Kanye West Reenact Their We...   \n",
      "2021-08-27 18:34:30  Female hummingbirds avoid sexual harassment by...   \n",
      "2021-08-27 18:34:12  Peloton says it’s subject to DOJ, DHS, and SEC...   \n",
      "2021-08-27 18:30:48  How Blue Origin, SpaceX, Virgin Galactic space...   \n",
      "2021-08-27 18:28:47  Louisville Cardinals suspend men's basketball ...   \n",
      "2021-08-27 18:15:52  T-Mobile CEO apologizes for data breach, annou...   \n",
      "2021-08-24 16:55:58  Gavin Newsom’s Recall Election Divides Silicon...   \n",
      "2021-08-24 13:12:20  House Democrats Struggle for Votes to Pass $3....   \n",
      "2021-08-27 09:00:14  Justice Breyer on Retirement and the Role of P...   \n",
      "2021-08-26 14:51:45                                 Politics this week   \n",
      "2021-08-24 15:56:00  Starvation stalks Afghanistan, politics must b...   \n",
      "2021-08-26 22:30:22  Analysis: President DeSantis? Florida voters s...   \n",
      "2021-08-24 15:28:40  Paralympics opening ceremony: pandemic, politi...   \n",
      "2021-08-25 01:26:00  Hong Kong lawyers attacked by pro-Beijing medi...   \n",
      "2021-08-25 17:36:32  After Mark Sanford lost a GOP House primary to...   \n",
      "2021-08-24 14:01:16  As ISS Enters Its Final Years, Politics Take C...   \n",
      "2021-08-27 05:00:09  The Greens in the UK are on the brink of power...   \n",
      "2021-08-25 18:13:08  Joe Manchin Faces Protests from the Left at Ho...   \n",
      "2021-08-25 23:09:19  Kenya's Deputy President Ruto campaigns for 'H...   \n",
      "2021-08-26 17:13:19  Only bold policies will win back Labour voters...   \n",
      "2021-08-24 17:02:20  A California judge just struck down Prop 22: N...   \n",
      "2021-08-24 13:12:36  Kathy Hochul sworn in as first female governor...   \n",
      "2021-08-27 03:41:37  The White House says it is 'not a day for poli...   \n",
      "2021-08-26 19:54:30  Michel Barnier to run in French presidential e...   \n",
      "2021-08-25 18:08:37  Capitol attack committee issues sweeping reque...   \n",
      "2021-08-26 14:00:00  How COVID, Inequality and Politics Make a Vici...   \n",
      "\n",
      "                                                                author  \\\n",
      "publishedAt                                                              \n",
      "2021-08-27 22:37:52  Shawn Boburg, Meagan Flynn, Alex Horton, Ellen...   \n",
      "2021-08-27 22:21:00                Ray Sanchez and Cheri Mossburg, CNN   \n",
      "2021-08-27 21:31:00                                      Bryan Fonseca   \n",
      "2021-08-27 21:25:00                                                      \n",
      "2021-08-27 20:50:00                                       Florence Ion   \n",
      "2021-08-27 20:10:07                                         MATT DIXON   \n",
      "2021-08-27 20:03:00                                    Maggie Fox, CNN   \n",
      "2021-08-27 19:40:09                                      Amanda Macias   \n",
      "2021-08-27 19:37:07                                      Matthew Bloch   \n",
      "2021-08-27 19:36:29                                               None   \n",
      "2021-08-27 19:16:40                                     Kelsey Ramirez   \n",
      "2021-08-27 19:13:45                         Dave Clarke, Tom Hamburger   \n",
      "2021-08-27 19:10:00             Eric Bradner and Dianne Gallagher, CNN   \n",
      "2021-08-27 18:57:04                                    Michael Shapiro   \n",
      "2021-08-27 18:53:13                                     Janelle Okwodu   \n",
      "2021-08-27 18:34:30                                      Hannah Sparks   \n",
      "2021-08-27 18:34:12                                     Mitchell Clark   \n",
      "2021-08-27 18:30:48                                       Charlie Wood   \n",
      "2021-08-27 18:28:47                                     Mark Schlabach   \n",
      "2021-08-27 18:15:52  https://www.engadget.com/about/editors/igor-bo...   \n",
      "2021-08-24 16:55:58                                     Arielle Pardes   \n",
      "2021-08-24 13:12:20                                 The New York Times   \n",
      "2021-08-27 09:00:14                                        Adam Liptak   \n",
      "2021-08-26 14:51:45                                      The Economist   \n",
      "2021-08-24 15:56:00                                            Reuters   \n",
      "2021-08-26 22:30:22    Analysis by Chris Cillizza, CNN Editor-at-large   \n",
      "2021-08-24 15:28:40             Paul MacInnes at Tokyo Olympic Stadium   \n",
      "2021-08-25 01:26:00                                            Reuters   \n",
      "2021-08-25 17:36:32               insider@insider.com (John L. Dorman)   \n",
      "2021-08-24 14:01:16                                          Tom Nardi   \n",
      "2021-08-27 05:00:09                                       Andy Beckett   \n",
      "2021-08-25 18:13:08                                     Philip Elliott   \n",
      "2021-08-25 23:09:19                   https://www.facebook.com/bbcnews   \n",
      "2021-08-26 17:13:19                                            Letters   \n",
      "2021-08-24 17:02:20                                      Annie Siebert   \n",
      "2021-08-24 13:12:36                          Ed Pilkington in New York   \n",
      "2021-08-27 03:41:37              cteh@businessinsider.com (Cheryl Teh)   \n",
      "2021-08-26 19:54:30                               Agence France-Presse   \n",
      "2021-08-25 18:08:37                                          Maya Yang   \n",
      "2021-08-26 14:00:00              Emily Mendenhall, Clarence C. Gravlee   \n",
      "\n",
      "                                                                   url  \\\n",
      "publishedAt                                                              \n",
      "2021-08-27 22:37:52  https://www.washingtonpost.com/national-securi...   \n",
      "2021-08-27 22:21:00  https://www.cnn.com/2021/08/27/us/sirhan-sirha...   \n",
      "2021-08-27 21:31:00  https://deadspin.com/lauri-markkanen-trade-mea...   \n",
      "2021-08-27 21:25:00  https://www.cbssports.com/fantasy/football/new...   \n",
      "2021-08-27 20:50:00  https://gizmodo.com/you-can-use-windows-11-on-...   \n",
      "2021-08-27 20:10:07  https://www.politico.com/states/florida/story/...   \n",
      "2021-08-27 20:03:00  https://www.cnn.com/2021/08/27/health/teacher-...   \n",
      "2021-08-27 19:40:09  https://www.cnbc.com/2021/08/27/covid-origin-r...   \n",
      "2021-08-27 19:37:07  https://www.nytimes.com/interactive/2021/us/hu...   \n",
      "2021-08-27 19:36:29  https://www.npr.org/sections/goatsandsoda/2021...   \n",
      "2021-08-27 19:16:40  https://www.foxbusiness.com/personal-finance/f...   \n",
      "2021-08-27 19:13:45  https://www.washingtonpost.com/politics/januar...   \n",
      "2021-08-27 19:10:00  https://www.cnn.com/2021/08/27/politics/texas-...   \n",
      "2021-08-27 18:57:04  https://www.si.com/soccer/2021/08/27/jay-glaze...   \n",
      "2021-08-27 18:53:13  https://www.vogue.com/article/kanye-west-kim-k...   \n",
      "2021-08-27 18:34:30  https://nypost.com/2021/08/27/female-hummingbi...   \n",
      "2021-08-27 18:34:12  https://www.theverge.com/2021/8/27/22644743/pe...   \n",
      "2021-08-27 18:30:48  https://www.cnbc.com/2021/08/27/how-blue-origi...   \n",
      "2021-08-27 18:28:47  https://www.espn.com/mens-college-basketball/s...   \n",
      "2021-08-27 18:15:52  https://www.engadget.com/t-mobile-mandiant-sec...   \n",
      "2021-08-24 16:55:58  https://www.wired.com/story/gavin-newsom-recal...   \n",
      "2021-08-24 13:12:20  https://www.nytimes.com/live/2021/08/24/us/bid...   \n",
      "2021-08-27 09:00:14  https://www.nytimes.com/2021/08/27/us/politics...   \n",
      "2021-08-26 14:51:45  https://www.economist.com/the-world-this-week/...   \n",
      "2021-08-24 15:56:00  https://www.reuters.com/world/asia-pacific/sta...   \n",
      "2021-08-26 22:30:22  https://www.cnn.com/2021/08/26/politics/desant...   \n",
      "2021-08-24 15:28:40  https://amp.theguardian.com/sport/2021/aug/24/...   \n",
      "2021-08-25 01:26:00  https://www.reuters.com/world/china/hong-kong-...   \n",
      "2021-08-25 17:36:32  https://www.businessinsider.com/mark-sanford-r...   \n",
      "2021-08-24 14:01:16  https://hackaday.com/2021/08/24/as-iss-enters-...   \n",
      "2021-08-27 05:00:09  https://amp.theguardian.com/commentisfree/2021...   \n",
      "2021-08-25 18:13:08  https://time.com/6092770/joe-manchin-william-b...   \n",
      "2021-08-25 23:09:19   https://www.bbc.co.uk/news/world-africa-58246207   \n",
      "2021-08-26 17:13:19  https://amp.theguardian.com/politics/2021/aug/...   \n",
      "2021-08-24 17:02:20  http://techcrunch.com/2021/08/24/a-california-...   \n",
      "2021-08-24 13:12:36  https://amp.theguardian.com/us-news/2021/aug/2...   \n",
      "2021-08-27 03:41:37  https://www.businessinsider.com/jen-psaki-not-...   \n",
      "2021-08-26 19:54:30  https://amp.theguardian.com/world/2021/aug/26/...   \n",
      "2021-08-25 18:08:37  https://amp.theguardian.com/us-news/2021/aug/2...   \n",
      "2021-08-26 14:00:00  https://www.scientificamerican.com/article/how...   \n",
      "\n",
      "                                                                  text  \\\n",
      "publishedAt                                                              \n",
      "2021-08-27 22:37:52  the   u.s. service members killed in the  kabu...   \n",
      "2021-08-27 22:21:00  sirhan  sirhan  sen.  robert  f.  kennedy is c...   \n",
      "2021-08-27 21:31:00  lauri  markkanen traded to the  cleveland  cav...   \n",
      "2021-08-27 21:25:00    fantasy  football  draft  prep  best  adp va...   \n",
      "2021-08-27 20:50:00  you  can  use  windows  on  unsupported  hardw...   \n",
      "2021-08-27 20:10:07  florida starts turning on  de santis\\n\\n\\n\\n\\n...   \n",
      "2021-08-27 20:03:00  unvaccinated, unmasked teacher infected more t...   \n",
      "2021-08-27 19:40:09   report  u.s. intelligence agencies are divide...   \n",
      "2021-08-27 19:37:07  map  tracking  hurricane  idas  path   the  ne...   \n",
      "2021-08-27 19:36:29  does  delta  variant  pose  less  risk  with  ...   \n",
      "2021-08-27 19:16:40  fed  chair  powell says inflation surge will b...   \n",
      "2021-08-27 19:13:45  house  jan.  committee seeks information from ...   \n",
      "2021-08-27 19:10:00  texas  house approves  gop voting restrictions...   \n",
      "2021-08-27 18:57:04  jay  glazer celebrates  cristiano  ronaldo joi...   \n",
      "2021-08-27 18:53:13  kim  kardashian and  kanye  west  reenact  the...   \n",
      "2021-08-27 18:34:30  female hummingbirds avoid sexual harassment by...   \n",
      "2021-08-27 18:34:12  peloton says its subject to  doj, dhs, and sec...   \n",
      "2021-08-27 18:30:48  how  blue  origin,  space x,  virgin  galactic...   \n",
      "2021-08-27 18:28:47  louisville  cardinals suspend men is basketbal...   \n",
      "2021-08-27 18:15:52  t mobile  ceo apologizes for data breach, anno...   \n",
      "2021-08-24 16:55:58  gavin  newsoms  recall  election  divides  sil...   \n",
      "2021-08-24 13:12:20  house narrowly passes . trillion budget bluepr...   \n",
      "2021-08-27 09:00:14  justice  breyer on  retirement and the  role o...   \n",
      "2021-08-26 14:51:45  politics this week   the  economist the  econo...   \n",
      "2021-08-24 15:56:00  starvation stalks  afghanistan, politics must ...   \n",
      "2021-08-26 22:30:22  president  de santis  florida voters say 'no.'...   \n",
      "2021-08-24 15:28:40  paralympics opening ceremony pandemic, politic...   \n",
      "2021-08-25 01:26:00  hong  kong lawyers attacked by pro beijing med...   \n",
      "2021-08-25 17:36:32  mark  sanford  sons  said  loss to  trump back...   \n",
      "2021-08-24 14:01:16  as  iss  enters  its  final  years,  politics ...   \n",
      "2021-08-27 05:00:09  the  greens are on the brink of power  is it m...   \n",
      "2021-08-25 18:13:08  joe  manchin  faces  protests from the  left i...   \n",
      "2021-08-25 23:09:19  kenya is  deputy  president  ruto campaigns fo...   \n",
      "2021-08-26 17:13:19  only bold policies will win back  labour voter...   \n",
      "2021-08-24 17:02:20  a  california judge just struck down  prop   n...   \n",
      "2021-08-24 13:12:36  kathy  hochul sworn in as first female governo...   \n",
      "2021-08-27 03:41:37  jen  psaki  it is ' not a  day for  politics' ...   \n",
      "2021-08-26 19:54:30  michel  barnier to run in  french presidential...   \n",
      "2021-08-25 18:08:37  capitol attack committee issues sweeping reque...   \n",
      "2021-08-26 14:00:00  how  covid,  inequality and  politics  make a ...   \n",
      "\n",
      "                     keyword1  keyword2  keyword3  \\\n",
      "publishedAt                                         \n",
      "2021-08-27 22:37:52       NaN       NaN       NaN   \n",
      "2021-08-27 22:21:00       NaN       NaN       NaN   \n",
      "2021-08-27 21:31:00       NaN       NaN       NaN   \n",
      "2021-08-27 21:25:00       NaN       NaN       NaN   \n",
      "2021-08-27 20:50:00       NaN       NaN       NaN   \n",
      "2021-08-27 20:10:07       NaN       NaN       NaN   \n",
      "2021-08-27 20:03:00       NaN       NaN       NaN   \n",
      "2021-08-27 19:40:09       NaN       NaN       NaN   \n",
      "2021-08-27 19:37:07       NaN       NaN       NaN   \n",
      "2021-08-27 19:36:29       NaN       NaN       NaN   \n",
      "2021-08-27 19:16:40       NaN       NaN       NaN   \n",
      "2021-08-27 19:13:45       NaN       NaN       NaN   \n",
      "2021-08-27 19:10:00       NaN       NaN       NaN   \n",
      "2021-08-27 18:57:04       NaN       NaN       NaN   \n",
      "2021-08-27 18:53:13       NaN       NaN       NaN   \n",
      "2021-08-27 18:34:30       NaN       NaN       NaN   \n",
      "2021-08-27 18:34:12       NaN       NaN       NaN   \n",
      "2021-08-27 18:30:48       NaN       NaN       NaN   \n",
      "2021-08-27 18:28:47       NaN       NaN       NaN   \n",
      "2021-08-27 18:15:52       NaN       NaN       NaN   \n",
      "2021-08-24 16:55:58       NaN       NaN       NaN   \n",
      "2021-08-24 13:12:20       NaN       NaN       NaN   \n",
      "2021-08-27 09:00:14       NaN       NaN       NaN   \n",
      "2021-08-26 14:51:45       NaN       NaN       NaN   \n",
      "2021-08-24 15:56:00       NaN       NaN       NaN   \n",
      "2021-08-26 22:30:22       NaN       NaN       NaN   \n",
      "2021-08-24 15:28:40       NaN       NaN       NaN   \n",
      "2021-08-25 01:26:00       NaN       NaN       NaN   \n",
      "2021-08-25 17:36:32       NaN       NaN       NaN   \n",
      "2021-08-24 14:01:16       NaN       NaN       NaN   \n",
      "2021-08-27 05:00:09       NaN       NaN       NaN   \n",
      "2021-08-25 18:13:08       NaN       NaN       NaN   \n",
      "2021-08-25 23:09:19       NaN       NaN       NaN   \n",
      "2021-08-26 17:13:19       NaN       NaN       NaN   \n",
      "2021-08-24 17:02:20       NaN       NaN       NaN   \n",
      "2021-08-24 13:12:36       NaN       NaN       NaN   \n",
      "2021-08-27 03:41:37       NaN       NaN       NaN   \n",
      "2021-08-26 19:54:30       NaN       NaN       NaN   \n",
      "2021-08-25 18:08:37       NaN       NaN       NaN   \n",
      "2021-08-26 14:00:00       NaN       NaN       NaN   \n",
      "\n",
      "                                                  keywords  \n",
      "publishedAt                                                 \n",
      "2021-08-27 22:37:52               (kabul, service, killed)  \n",
      "2021-08-27 22:21:00            (kennedy, extreme, justice)  \n",
      "2021-08-27 21:31:00              (markkanen, traded, club)  \n",
      "2021-08-27 21:25:00        (fantasy, experience, football)  \n",
      "2021-08-27 20:50:00         (requirements, club, deadspin)  \n",
      "2021-08-27 20:10:07                (magazine, judge, mask)  \n",
      "2021-08-27 20:03:00                  (mask, justice, kids)  \n",
      "2021-08-27 19:40:09             (markets, squawk, quotes,)  \n",
      "2021-08-27 19:37:07                 (tracking, york, skip)  \n",
      "2021-08-27 19:36:29  (expandcollapse, likely, coronavirus)  \n",
      "2021-08-27 19:16:40        (markets, 'tugofwar', business)  \n",
      "2021-08-27 19:13:45                (request, attack, skip)  \n",
      "2021-08-27 19:10:00               (texas, voting, january)  \n",
      "2021-08-27 18:57:04              (glazer, joins, extended)  \n",
      "2021-08-27 18:53:13               (kardashian, skip, main)  \n",
      "2021-08-27 18:34:30        (jacobin, sexual, impeachment')  \n",
      "2021-08-27 18:34:12                (injuries, verge, doj,)  \n",
      "2021-08-27 18:30:48                (ozone, space, quotes,)  \n",
      "2021-08-27 18:28:47             (borzello, jeff, jonathan)  \n",
      "2021-08-27 18:15:52            (apologizes, verizon, home)  \n",
      "2021-08-24 16:55:58                (facebook, like, taxes)  \n",
      "2021-08-24 13:12:20             (citizens, extend, voting)  \n",
      "2021-08-27 09:00:14                (justice, breyer, size)  \n",
      "2021-08-26 14:51:45               (executive, week, japan)  \n",
      "2021-08-24 15:56:00            (welcome, reuterscom, beta)  \n",
      "2021-08-26 22:30:22        (question, presidency, santis')  \n",
      "2021-08-24 15:28:40              (tokyo, zealand, opinion)  \n",
      "2021-08-25 01:26:00          (beijing, exclusive, reuters)  \n",
      "2021-08-25 17:36:32                 (stylized, next, word)  \n",
      "2021-08-24 14:01:16                (hacks, hackaday, jaxa)  \n",
      "2021-08-27 05:00:09                   (party, home, sport)  \n",
      "2021-08-25 18:13:08            (next, organizers, manchin)  \n",
      "2021-08-25 23:09:19                 (kenya, moment', next)  \n",
      "2021-08-26 17:13:19                 (back, sport, culture)  \n",
      "2021-08-24 17:02:20           (judge, workers, organizing)  \n",
      "2021-08-24 13:12:36                (york, governor, kathy)  \n",
      "2021-08-27 03:41:37                    (kabul, word, next)  \n",
      "2021-08-26 19:54:30                (brexit, home, opinion)  \n",
      "2021-08-25 18:08:37          (requests, executive, attack)  \n",
      "2021-08-26 14:00:00        (inequities, covid, inequality)  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Search Twitter API\n",
    "## Using Important Words & Phrases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Tweets class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "class Tweets():\n",
    "    # keywords = news.all_news_df[\"keywords\"]\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, logger=logging):\n",
    "        self.logger = logging.basicConfig(filename='tweets.log', filemode='w',\n",
    "                                         format=f'%(asctime)s - %(levelname)s - %(message)s')\n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = access_token\n",
    "        self.access_token_secret = access_token_secret\n",
    "\n",
    "    def tweepy_auth(self):\n",
    "        \"\"\"Authorize tweepy API\"\"\"\n",
    "\n",
    "        self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "        self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "\n",
    "        # create API object\n",
    "        self.api = API(self.auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "        try:\n",
    "            self.api.verify_credentials()\n",
    "            logging.info(\"Tweepy API Authenticated\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during Tweepy authentication: {e}\")\n",
    "            raise e \n",
    "        return self.api\n",
    "    \n",
    "    \n",
    "    def tweet_search(self, query):\n",
    "        \"\"\"Search for tweets within previous 7 days.\n",
    "            Inputs: \n",
    "                https-encoded query\n",
    "                language\n",
    "                'until' date\n",
    "                geocode (latitude/longitude)\n",
    "            Returns: \n",
    "                Tweet object\n",
    "        \"\"\"\n",
    "        self.tweet_search_list = []\n",
    "\n",
    "        # search parameters\n",
    "        # query = {\n",
    "        #     'tweet.fields': 'attachments,author_id,created_at,geo,id,public_metrics,source,text',\n",
    "        #     'expansions': 'geo.place_id,attachments.media_keys', \n",
    "        #     'place.fields': 'country,geo,id,name', \n",
    "        #     'user.fields': 'created_at,description,id,location,name,username,verified'\n",
    "        #     }\n",
    "        # pquery = urllib.parse.urlencode(query)\n",
    "\n",
    "        # latitude & longitude of Colombus, OH, USA\n",
    "        latitude = '39.9828671'\n",
    "        longitude = '-83.1309131'\n",
    "        # radius of united states\n",
    "        radius = '3881mi'\n",
    "\n",
    "        query_result = tweepy.Cursor(self.api.search, q=query, lang='en')# until={\n",
    "                                    # date.today()}) #geocode=[latitude, longitude, radius])\n",
    "        #print(query_result.items())\n",
    "        with open('search_tweets.json', 'w') as f:\n",
    "            for status in query_result.items():\n",
    "        #     self.tweet_search_list.append(status)\n",
    "            # return self.tweet_search_list\n",
    "        \n",
    "                # Tweet ID\n",
    "                tweet_id = status.id\n",
    "                # User ID\n",
    "                user_id = status.user.id\n",
    "                # Username\n",
    "                username = status.user.name\n",
    "                # creation date\n",
    "                create_time = status.user.creation_date\n",
    "\n",
    "                # Tweet\n",
    "                if status.truncated == True:\n",
    "                    tweet = status.extended_tweet['full_text']\n",
    "                    hashtags = status.extended_tweet['entities']['hashtags']\n",
    "                else:\n",
    "                    tweet = status.text\n",
    "                    hashtags = status.entities['hashtags']\n",
    "                # Read hashtags\n",
    "                hashtags = read_hashtags(hashtags)\n",
    "            \n",
    "                self.tweet_search_list.append(status)\n",
    "        \n",
    "            json.dump(self.tweet_search_list, f)\n",
    "\n",
    "        self.tweet_search_df = pd.DataFrame(self.tweet_search_list, columns=[\"tweet_id\", \"user_id\", \"create_time\", \"status_text\"]) # TODO just combine all the dfs \n",
    "\n",
    "        # TODO change to datetime\n",
    "        # self.tweet_search_df['created_at'].apply(\n",
    "        #     lambda row: datetime.strptime(\n",
    "        #         row, '%Y-%m-%dT%H:%M:%SZ'),\n",
    "        #     axis=0)\n",
    "\n",
    "        return self.tweet_search_df\n",
    "    \n",
    "        \n",
    "    def tweet_trends(self):\n",
    "        # returns JSON\n",
    "        self.tweet_trends_list = []\n",
    "\n",
    "        # shows trends available by location\n",
    "        # locations = self.api.trends_available()\n",
    "\n",
    "        # trends by country\n",
    "        self.location = sys.argv[1] # user location as argument variable\n",
    "        self.geo = geocoder.osm(self.location) # object with latitude & longitude of user location\n",
    "        self.closest_trends = self.api.trends_closest(lat=self.geo.lat, long=self.geo.lng)\n",
    "\n",
    "        # trends = tweepy.Cursor(self.api.trends_place(closest_loc[0]))\n",
    "        # trends = tweepy.Cursor(self.api.trends_place(closest_loc[0]['woeid']))\n",
    "\n",
    "        with open(\"twitter_trends.json\", \"w\") as f:\n",
    "            # write results to JSON file\n",
    "            json.dump(self.closest_trends, f)\n",
    "\n",
    "        with open(\"twitter_trends.json\", \"r\") as file:\n",
    "            # create Python object from JSON\n",
    "            twitter_trends_json = file.read().split(\"\\n\")\n",
    "\n",
    "            for tweet in twitter_trends_json:\n",
    "                tweet_obj = json.loads(tweet)\n",
    "\n",
    "                # add info to top_headlines list/dict\n",
    "                self.tweet_trends_list.append(tweet_obj)\n",
    "\n",
    "        # for trend in self.closest_trends:#.items():\n",
    "        #     self.tweet_trends_list.append(trend)\n",
    "            # return self.tweet_trends_list\n",
    "\n",
    "            self.tweet_trends_df = pd.DataFrame(self.tweet_trends_list)\n",
    "            # TODO call .clean_tweets() to put clean data into df\n",
    "\n",
    "        return self.tweet_trends_df \n",
    "    \n",
    "    def clean_tweets(self, tweets):\n",
    "        # use slang.txt\n",
    "        # https://www.geeksforgeeks.org/python-efficient-text-data-cleaning/\n",
    "        pass\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "\n",
    "t = Tweets(consumer_key, consumer_secret,access_token, access_token_secret)\n",
    "auth = t.tweepy_auth()\n",
    "\n",
    "# apply search to keywords\n",
    "t.tweet_search_df[\"tweet_count\"] = news.all_news_df[\"keywords\"].map(\n",
    "    t.tweet_search)\n",
    "\n",
    "print(t.tweet_search_df) \n",
    "\n",
    "# keywords = news.all_news_df[\"keywords\"]\n",
    "\n",
    "# # authenticate tweepy\n",
    "# tweets = Tweets(consumer_key, consumer_secret,\n",
    "#                 access_token, access_token_secret)\n",
    "# auth = tweets.tweepy_auth()\n",
    "# # search for tweets - query is built-in for poltiics\n",
    "# tweets.tweet_search()\n",
    "# # get tweet trends\n",
    "# tweets.tweet_trends()  # TODO perform pagination\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in __instancecheck__",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-8f5f91c63afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     t.tweet_search)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_search_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# keywords = news.all_news_df[\"keywords\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m         self.to_string(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             )\n\u001b[0;32m-> 1131\u001b[0;31m             return fmt.DataFrameRenderer(formatter).to_string(\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mstring_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_string_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions_info\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_string_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_empty_info_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_width\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_dot_separators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \"\"\"\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols_without_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_strcols_without_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             )\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             fmt_values = _make_fixed_width(\n\u001b[1;32m    806\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_colwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    819\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mleading_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" {_format(v)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1309\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPandasObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                 \u001b[0;31m# object dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 13 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_eng_projects/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m         self.to_string(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded in __instancecheck__"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# define stream listener class\n",
    "class TwitterStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(TwitterStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open('tweets.txt', 'w')\n",
    "        self.tweet_list = []\n",
    "\n",
    "    def on_status(self, status): # returns JSON \n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n')\n",
    "\n",
    "        # Tweet ID\n",
    "        tweet_id = status.id\n",
    "        # User ID\n",
    "        user_id = status.user.id\n",
    "        # Username\n",
    "        username = status.user.name\n",
    "        # creation date\n",
    "        create_time = status.user.creation_date\n",
    "\n",
    "        # Tweet\n",
    "        if status.truncated == True:\n",
    "            tweet = status.extended_tweet['full_text']\n",
    "            hashtags = status.extended_tweet['entities']['hashtags']\n",
    "        else:\n",
    "            tweet = status.text\n",
    "            hashtags = status.entities['hashtags']\n",
    "        # Read hastags\n",
    "        hashtags = read_hashtags(hashtags)\n",
    "        # Retweet count\n",
    "        retweet_count = status.retweet_count\n",
    "        # Language\n",
    "        lang = status.lang\n",
    "        \n",
    "        # If tweet is not a retweet and tweet is in English\n",
    "        # if not hasattr(status, \"retweeted_status\") and lang == \"en\":\n",
    "        #     # Connect to database\n",
    "        #     dbConnect(user_id, username, tweet_id,\n",
    "        #               tweet, retweet_count, hashtags)\n",
    "\n",
    "\n",
    "\n",
    "        self.tweet_list.append(status)\n",
    "        self.num_tweets += 1\n",
    "\n",
    "        if self.num_tweets < 450:  # max stream rate is for the twitter API Client\n",
    "            return True\n",
    "        else:\n",
    "\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    \n",
    "\n",
    "        # flatten data to dataframe\n",
    "        # tweets = pd.json_normalize(self.tweet_list, record_path=['articles'])\n",
    "        self.tweets_df = pd.DataFrame(self.tweet_list, columns=[\n",
    "                                      \"tweet_id\", \"publishedAt\", \"userID\", \"text\", \"location\"])\n",
    "\n",
    "        return self.tweets_df\n",
    "\n",
    "        # if self.num_tweets < 450:  # max stream rate is for the twitter API Client\n",
    "        #     return True\n",
    "        # else:\n",
    "        #     return False\n",
    "        # self.file.close()\n",
    "    \n",
    "    # Extract hashtags\n",
    "    def read_hashtags(self, tag_list):\n",
    "        hashtags = []\n",
    "\n",
    "        for tag in tag_list:\n",
    "            hashtags.append(tag['text'])\n",
    "\n",
    "        return hashtags\n",
    "    \n",
    "    \n",
    "    def clean_tweets(self):\n",
    "\n",
    "        with open(\"tweets.json\", \"w\") as f:\n",
    "            # write tweets to json file\n",
    "            json.dump(tweet, f)\n",
    "\n",
    "        with open(\"tweets.json\", \"r\") as file:\n",
    "            # create python object from json\n",
    "            tweets_json = file.read().split(\"\\n\")\n",
    "\n",
    "            for tweet in tweets_json:\n",
    "                tweet_obj = json.loads(tweet)\n",
    "\n",
    "                #flatten nested fields\n",
    "                if 'quoted_status' in tweet_obj:\n",
    "                    tweet_obj['quote_tweet'] = tweet_obj['quoted_status']['extended_tweet']['full_text']\n",
    "                if 'user' in tweet_obj:\n",
    "                    tweet_obj['location'] = tweet_obj['user']['location']\n",
    "                # if 'created_at' in tweet_obj:\n",
    "                #     tweet_obj['created_at'] = pd.to_datetime(tweet)\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            return False  # false disconnects the stream\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "\n",
    "auth = t.tweepy_auth()\n",
    "# instantiate Tweet Stream Listener\n",
    "listener = TwitterStreamListener()\n",
    "# authenticate stream\n",
    "tweet_stream = tweepy.Stream(auth, listener)\n",
    "listener.on_status(tweet_stream)\n",
    "\n",
    "# print cleaned tweets df\n",
    "\n",
    "# print(news.all_news_df)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Stream' object has no attribute 'id'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-8704a51c8b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# authenticate stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweet_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print cleaned tweets df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-4451685aeff4>\u001b[0m in \u001b[0;36mon_status\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Tweet ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtweet_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# User ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stream' object has no attribute 'id'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Search TikTok\n",
    "## Using Important Words & Phrases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Search TikTok for videos related to keywords parsed from news articles\"\"\"\n",
    "\n",
    "fp = c['tiktokAuth']['s_v_web_id']\n",
    "\n",
    "class TikToks(TikTokApi):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TikTokApi, self).__init__()\n",
    "        self.tiktok_list = []\n",
    "\n",
    "    @Timer(\"Tiktok Download\")\n",
    "    def get_tiktok_trends(self, keywords):\n",
    "        # returns tiktok dictionary/JSON\n",
    "        self.api = TikTokApi()\n",
    "        self.api.get_instance(custom_verifyFp=fp, use_test_endpoints=True, use_selenium=True)\n",
    "        trends = self.api.by_hashtag(keywords)\n",
    "\n",
    "        with open(\"tiktoks.json\", \"w\") as f:\n",
    "            json.dump(trends, f)\n",
    "\n",
    "        with open(\"tiktoks.json\", \"r\") as file:\n",
    "            toks_json = file.read().split(\"\\n\")\n",
    "\n",
    "            # create json object for each tiktok\n",
    "            for tok in toks_json:\n",
    "                tok_obj = json.loads(tok)\n",
    "                \n",
    "                if 'id' in tok:\n",
    "                    tok_obj['userID'] = tok_obj['author']['id']\n",
    "                    tok_obj['postID'] = tok_obj['id']\n",
    "                if 'signature' in tok:\n",
    "                    tok_obj['user_bio'] = tok_obj['author']['signature']\n",
    "                if 'challenges' in tok:\n",
    "                    # iterate over multiples\n",
    "                    tok_obj['tagID'] = tok_obj['challenges']['id']\n",
    "                    tok_obj['tag_name'] = tok_obj['challenges']['title']\n",
    "                if 'createTime' in tok:\n",
    "                    tok_obj['createTime'] = tok_obj['createTime']\n",
    "                if 'desc' in tok:\n",
    "                    tok_obj['description'] = tok_obj['desc']\n",
    "                if 'stats' in tok:\n",
    "                    tok_obj['comment_count'] = tok_obj['stats']['commentCount']\n",
    "                    tok_obj['digg_count'] = tok_obj['stats']['diggCount']\n",
    "                    tok_obj['play_count'] = tok_obj['stats']['playCount']\n",
    "                    tok_obj['share_count'] = tok_obj['stats']['shareCount']\n",
    "                if 'video' in tok:\n",
    "                    tok_obj['videoID'] = tok_obj['itemList']['video']['id']\n",
    "                if 'sound' in tok:\n",
    "                    tok_obj['soundID'] = tok_obj['sound']['id']\n",
    "                    tok_obj['soundTitle'] = tok_obj['sound']['title']\n",
    "                    tok_obj['isOriginal'] = tok_obj['sound']['original']\n",
    "                if 'music' in tok:\n",
    "                    tok_obj['songID'] = tok_obj['music']['id']\n",
    "                    tok_obj['songTitle'] = tok_obj['music']['title']\n",
    "                \n",
    "                self.tiktok_list.append(tok_obj)\n",
    "\n",
    "            # create tiktok dataframe\n",
    "            self.toks_df = pd.DataFrame(self.tiktok_list)\n",
    "\n",
    "            # split df by columns corresponding to tables\n",
    "\n",
    "        return self.toks_df\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Add Late-Arriving Dimensions/Data\n",
    "### *data corresponding to 3 days before news hit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from timer import Timer\n",
    "from database import *\n",
    "from get_news import *\n",
    "import configparser\n",
    "\n",
    "# configure ConfigParser\n",
    "c = configparser.ConfigParser()\n",
    "c.read('config.ini')\n",
    "\n",
    "# references .config credentials\n",
    "host = c['database']['host']\n",
    "username = c['database']['user']\n",
    "password = c['database']['password']\n",
    "db = c['database']['database']\n",
    "\n",
    "news_api_key = c['newsAuth']['api_key']\n",
    "tiktok_id = c['tiktokAuth']['s_v_web_id']\n",
    "twitter_api_key = c['twitterAuth']['api_key']\n",
    "\n",
    "# instantiate DataBase class using .config files\n",
    "\n",
    "\n",
    "# news.request_pop_news()\n",
    "# news.get_top_headlines()\n",
    "\n",
    "# apply get_text function using urls from all_news df\n",
    "url_text = news.all_news_df['url'].apply(\n",
    "        lambda row: news.article_text(news.all_news_df['url']),\n",
    "        axis=1)\n",
    "# put url_text into df\n",
    "news.article_text_df['text'] = url_text\n",
    "\n",
    "# get keywords from article text\n",
    "\n",
    "# article_text_df['keys'] = keyword_extraction(article_text)\n",
    "\n",
    "# TODO test get_news & find order of key:value pairs\n",
    "news.article_text_df['keyword1'] = keywords[1]\n",
    "news.article_text_df['keyword2'] = keywords[2]\n",
    "news.article_text_df['keyword3'] = keywords[3]\n",
    "\n",
    "\n",
    "# execute mogrify - insert news into database\n",
    "postgres_db.execute_mogrify(connection, news.all_news_df, 'articles')\n",
    "\n",
    "# append text and keys to database\n",
    "postgres_db.execute_mogrify(connection, news.article_text_df, 'article_text')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Tally Up\n",
    "### Partition total mentions by day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mogrify stream\n",
    "postgres_db.execute_mogrify(connection, filtered_stream, 'stream_tweets')\n",
    "# mogrify batch tweets\n",
    "postgres_db.execute_mogrify(connection, batch_tweets, 'batch_tweets')\n",
    "# mogrify trends\n",
    "postgres_db.execute_mogrify(connection, tweet_trends, 'tweet_trends')\n",
    "# execute mogrify - insert news & keywords into database\n",
    "postgres_db.execute_mogrify(connection, news.all_news_df, 'articles')\n",
    "\n",
    "# TODO group by event? "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Plot & Analyze\n",
    "- On which platform (Twitter or TikTok) do folks engage with politics the most?\n",
    "- Where in the US is engagement the highest?\n",
    "- Which political events seem to cause the most reaction among youth?"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('data_eng_projects': conda)"
  },
  "interpreter": {
   "hash": "292a7ef3bed24448555716cf5e78212297c16b0757a55b8597bb1f802fb134d0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}